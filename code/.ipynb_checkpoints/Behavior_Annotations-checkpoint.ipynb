{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5c50f78",
   "metadata": {},
   "source": [
    "# Update behavior annotations in datasets\n",
    "\n",
    "#### Brandon Pratt, 10/04/2024\n",
    "\n",
    "Description: This notebook uses manual behavioral annotations from the anipose visualizer to append new behavioral annotations to a dataset. The general use case for this code is to refine predicted behavioral annotations as needed to retrain behavioral classifiers. \n",
    "\n",
    "### Workflow:\n",
    "\n",
    "1) Update behavioral annotations in the anipose visualizer (https://flyviz.biz/).\n",
    "\n",
    "2) Download .json file for each date that data within the dataset was collected.\n",
    "\n",
    "3) Create a new git branch (git branch NAME) and open this notebook.\n",
    "\n",
    "4) Specify the directory that contains the dataset (.pq) and .json files in the code below. \n",
    "\n",
    "5) Run the cells below and the dataset will be appended with a column called 'behavioral annotations', which contains the updated annotations. \n",
    "\n",
    "6) Optional: Assign a numerical value to each behavior for training classifers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2552f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import pathlib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1bd2bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# located and read data\n",
    "filename = 'CxHP8_gtACR1_grooming_trials.pq'\n",
    "file_path = pathlib.Path.cwd().parent.joinpath('data')\n",
    "data = pd.read_parquet(file_path.joinpath(filename), engine='pyarrow')\n",
    "\n",
    "# Get behavior annotations for each data file\n",
    "beh_col = pd.DataFrame(np.nan, index=np.arange(len(data)).tolist(), columns=['behavior_annotations'])\n",
    "data = data.join(beh_col) # add a behavior column initialized with NaNs to data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ecc1371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Trials = 33\n"
     ]
    }
   ],
   "source": [
    "# find all filenames in dataset\n",
    "unique_files = np.unique(data['fullfile']).tolist()\n",
    "n_files = len(unique_files)\n",
    "print(f'Number of Trials = {n_files}')\n",
    "\n",
    "'''Extract info needed to search through jsons for behavioral labels'''\n",
    "# iterate through unique file names and extarct fly and trial info\n",
    "info_df = pd.DataFrame(np.nan, index=np.arange(n_files).tolist(), columns=['fly id', 'trial id'])\n",
    "for j, name in enumerate(unique_files):\n",
    "    split_name = name.split('|')\n",
    "    info_df.loc[j,'fly id'] = split_name[1]  # fly #\n",
    "    info_df.loc[j,'trial id'] = split_name[2]  # session id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1959e0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flies to annotate:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['4.4.24|Fly 2_0|04042024_fly2_0 R10C1  str-cw-0 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R10C10  str-ccw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R10C5  str-cw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R10C6  str-ccw-0 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R1C14  rot-cw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R2C1  str-cw-0 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R2C15  rot-cw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R2C17  rot-ccw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R3C1  str-cw-0 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R3C9  str-ccw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R4C11  rot-cw-0 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R4C14  rot-cw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R4C17  rot-ccw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R4C3  str-cw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R5C12  rot-cw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R5C19  rot-ccw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R5C3  str-cw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R5C6  str-ccw-0 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R5C9  str-ccw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R6C11  rot-cw-0 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R6C13  rot-cw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R6C16  rot-ccw-0 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R6C19  rot-ccw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R6C2  str-cw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R7C18  rot-ccw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R7C4  str-cw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R7C9  str-ccw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R8C1  str-cw-0 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R8C19  rot-ccw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R8C8  str-ccw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R9C12  rot-cw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R9C18  rot-ccw-1 sec',\n",
       " '4.4.24|Fly 2_0|04042024_fly2_0 R9C6  str-ccw-0 sec']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Flies to annotate:')\n",
    "unique_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b67e6b",
   "metadata": {},
   "source": [
    "### Extract behavorial annotations from jsons\n",
    "\n",
    "Note: Each json data is only associated with a single date of collected data so the user needs to download all relevant jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a52a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# behavior annotation directory (all jsons will be found)\n",
    "json_path = pathlib.Path.cwd().parent.joinpath('data')\n",
    "json_list = glob.glob(str(json_path.joinpath('*.json')))\n",
    "merged_jsons = []\n",
    "\n",
    "# extract behavior annotations from each json and append them\n",
    "for json_path in json_list:\n",
    "    # Open and read the JSON file\n",
    "    with open(json_path, 'r') as file:\n",
    "        beh_labels = json.load(file)\n",
    "        merged_jsons.append(beh_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "726a9816",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 154.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# iterate through json files and add updated behavioral annotations to the dataset\n",
    "for i in tqdm(range(n_files)):\n",
    "    fly_id = info_df['fly id'][i]\n",
    "    trial_id = info_df['trial id'][i]\n",
    "    trial_flag = 0 # flag if the trial data is found\n",
    "\n",
    "    for j in range(len(merged_jsons)):\n",
    "        json_data = merged_jsons[j]\n",
    "        fly_keys = list(json_data.keys())\n",
    "\n",
    "        # check to see if fly id matches any of the fly keys\n",
    "        if np.isin(fly_id, fly_keys):\n",
    "            fly_data = json_data[fly_id]\n",
    "            trial_keys = list(fly_data.keys())\n",
    "\n",
    "            # check if trial id matches any session keys\n",
    "            if np.isin(trial_id, trial_keys):\n",
    "                trial_flag = 1 # update trial flag because data was found\n",
    "                trial_data = fly_data[trial_id]\n",
    "\n",
    "                # get behavior bout keys and append the behaviors to the data\n",
    "                beh_keys = list(trial_data.keys())\n",
    "                for bout in beh_keys:\n",
    "                    curr_bout = trial_data[bout]\n",
    "                    behavior = curr_bout['behavior']\n",
    "                    start_frame = curr_bout['start']\n",
    "                    if start_frame != None: #  Occurs if behavior is deleted\n",
    "\n",
    "                        # correct start frame to 0 if -1 (error in visualizer?)\n",
    "                        if start_frame == -1:\n",
    "                            start_frame = 0\n",
    "                        end_frame = curr_bout['end']\n",
    "\n",
    "                        # add information to data\n",
    "                        df_indices = data[data['fullfile'] == unique_files[i]].index\n",
    "                        data.loc[df_indices[int(start_frame):int(end_frame+1)], 'behavior_annotations'] = behavior\n",
    "                \n",
    "                # found data so no need to search other json files\n",
    "                break\n",
    "                \n",
    "    if trial_flag == 0:\n",
    "        print(f'{fly_id}_{trial_id} not found')\n",
    "            \n",
    "# save the data with update behavior annotations \n",
    "new_filename = f'{filename[0:-3]}_updated_annotations.pq'\n",
    "data.to_parquet(file_path.joinpath(new_filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
